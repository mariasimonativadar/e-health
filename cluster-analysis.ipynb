{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a79339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "from scipy.stats import (\n",
    "    kstest,\n",
    "    f_oneway,\n",
    "    ttest_ind,\n",
    "    kruskal,\n",
    "    mannwhitneyu,\n",
    "    chi2_contingency,\n",
    "    fisher_exact\n",
    ")\n",
    "\n",
    "from statsmodels.stats.multitest import multipletests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc016aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns found: ['age', 'gender', 'education', 'marital', 'income', 'AUDIT_total_robust', 'DAST_total_robust', 'IAT_total_robust', 'PGSI_total_robust', 'PCL5_total_robust', 'MSPSS_total_robust', 'SWLS_total_robust', 'WHO5_total_robust', 'cluster']\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"clustered_sample.csv\"   \n",
    "SEP = \";\"                                 \n",
    "CLUSTER_COL = \"cluster\"                     \n",
    "OUTPUT_CSV = \"cluster_summary_table.csv\"\n",
    "OUTPUT_XLSX = \"cluster_summary_table.xlsx\"\n",
    "\n",
    "# --- LOAD DATA (IMPORTANT PART) ---\n",
    "df = pd.read_csv(DATA_PATH, sep=\",\")   # or just pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Clean possible spaces/BOM from column names\n",
    "df.columns = (\n",
    "    df.columns\n",
    "      .str.strip()            # remove spaces at start/end\n",
    "      .str.replace('\\ufeff', '', regex=False)  # remove BOM if present\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Columns found:\", df.columns.tolist())  # debug: see real names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04f2ff43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) DEMOGRAPHIC / CATEGORICAL VARIABLES (ORDERED)\n",
    "DEMO_CATEGORICAL = [\"gender\", \"education\", \"marital\", \"income_cat\"]\n",
    "\n",
    "# 2) OTHER NUMERIC VARIABLES\n",
    "OTHER_NUMERIC = [\n",
    "    \"AUDIT_total_robust\",\n",
    "    \"DAST_total_robust\",\n",
    "    \"IAT_total_robust\",\n",
    "    \"PGSI_total_robust\",\n",
    "    \"PCL5_total_robust\",\n",
    "    \"MSPSS_total_robust\",\n",
    "    \"SWLS_total_robust\",\n",
    "    \"WHO5_total_robust\",\n",
    "]\n",
    "\n",
    "\n",
    "# Mapping from numeric codes to labels for categorical vars\n",
    "CATEGORY_LABELS = {\n",
    "    \"gender\": {\n",
    "        0: \"Male\",\n",
    "        1: \"Female\",\n",
    "        2: \"Non-binary\",\n",
    "        3: \"Prefer not to say\",\n",
    "    },\n",
    "    \"education\": {\n",
    "        5: \"Elementary school\",\n",
    "        8: \"Middle school\",\n",
    "        13: \"High School\",\n",
    "        18: \"Bachelor's Degree\",\n",
    "        22: \"Master's Degree\",\n",
    "        25: \"Doctoral Degree\",\n",
    "    },\n",
    "    \"marital\": {\n",
    "        0: \"Single\",\n",
    "        1: \"Married\",\n",
    "        2: \"Divorced\",\n",
    "        3: \"Widowed\",\n",
    "        4: \"Separated\",\n",
    "        5: \"Prefer not to say\",\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# Pretty labels for left column\n",
    "DISPLAY_NAMES = {\n",
    "    \"gender\": \"Gender\",\n",
    "    \"education\": \"Education level\",\n",
    "    \"marital\": \"Marital status\",\n",
    "    \"income_cat\": \"Income bracket\",\n",
    "    \"AUDIT_total_robust\": \"Alcohol use (AUDIT)\",\n",
    "    \"DAST_total_robust\": \"Drug use (DAST)\",\n",
    "    \"IAT_total_robust\": \"Internet Addiction (IAT)\",\n",
    "    \"PGSI_total_robust\": \"Gambling (PGSI)\",\n",
    "    \"PCL5_total_robust\": \"Trauma (PCL-5)\",\n",
    "    \"MSPSS_total_robust\": \"Social Support (MSPSS)\",\n",
    "    \"SWLS_total_robust\": \"Life Satisfaction (SWLS)\",\n",
    "    \"WHO5_total_robust\": \"Well-being (WHO-5)\",\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58b1589a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_p_value(p):\n",
    "    if pd.isna(p):\n",
    "        return \"\"\n",
    "    if p < 0.001:\n",
    "        return \"<0.001\"\n",
    "    return f\"{p:.3f}\"\n",
    "\n",
    "def summarize_numeric(df, var, cluster_col):\n",
    "    \"\"\"For numeric variables: median (Q1; Q3) + Kruskal-Wallis\"\"\"\n",
    "    result = {}\n",
    "    groups = {}\n",
    "\n",
    "    for cl, sub in df.groupby(cluster_col):\n",
    "        values = sub[var].dropna().astype(float)\n",
    "        groups[cl] = values\n",
    "        if len(values) == 0:\n",
    "            result[cl] = \"\"\n",
    "        else:\n",
    "            median = np.median(values)\n",
    "            q1 = np.percentile(values, 25)\n",
    "            q3 = np.percentile(values, 75)\n",
    "            result[cl] = f\"{median:.1f} ({q1:.1f}; {q3:.1f})\"\n",
    "\n",
    "    valid = [g for g in groups.values() if len(g) > 0]\n",
    "    if len(valid) >= 2:\n",
    "        _, p = stats.kruskal(*valid)\n",
    "    else:\n",
    "        p = np.nan\n",
    "\n",
    "    result[\"p\"] = format_p_value(p)\n",
    "    return result\n",
    "\n",
    "def summarize_categorical(df, var, cluster_col):\n",
    "    \"\"\"For categorical variables: mode + % + chi-square test\"\"\"\n",
    "    result = {}\n",
    "\n",
    "    if var in CATEGORY_LABELS:\n",
    "        mapping = CATEGORY_LABELS[var]\n",
    "        series_all = df[var].map(mapping)\n",
    "    else:\n",
    "        series_all = df[var].astype(str)\n",
    "\n",
    "    for cl, sub in df.groupby(cluster_col):\n",
    "        series = series_all.loc[sub.index].dropna()\n",
    "        if len(series) == 0:\n",
    "            result[cl] = \"\"\n",
    "        else:\n",
    "            counts = series.value_counts()\n",
    "            mode_label = counts.idxmax()\n",
    "            pct = 100 * counts.max() / len(series)\n",
    "            result[cl] = f\"{mode_label} ({pct:.0f}%)\"\n",
    "\n",
    "    contingency = pd.crosstab(df[var], df[cluster_col])\n",
    "    if contingency.shape[0] >= 2 and contingency.shape[1] >= 2:\n",
    "        _, p, _, _ = stats.chi2_contingency(contingency)\n",
    "    else:\n",
    "        p = np.nan\n",
    "\n",
    "    result[\"p\"] = format_p_value(p)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40dba789",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.strip().str.replace(\"\\ufeff\", \"\", regex=False)\n",
    "\n",
    "# Convert cluster to string for consistent grouping\n",
    "df[CLUSTER_COL] = df[CLUSTER_COL].astype(str)\n",
    "\n",
    "\n",
    "# Convert income to categorical (Option B)\n",
    "df[\"income_cat\"] = pd.cut(\n",
    "    df[\"income\"],\n",
    "    bins=[0, 20000, 40000, 60000, np.inf],\n",
    "    labels=[\"<20k\", \"20k‚Äì40k\", \"40k‚Äì60k\", \">60k\"],\n",
    "    right=False\n",
    ")\n",
    "\n",
    "clusters = sorted(df[CLUSTER_COL].unique())\n",
    "cluster_counts = {cl: (df[CLUSTER_COL] == cl).sum() for cl in clusters}\n",
    "cluster_col_names = [f\"Cluster {cl} (n={cluster_counts[cl]})\" for cl in clusters]\n",
    "\n",
    "rows = []\n",
    "# 1) DEMOGRAPHIC CATEGORICAL\n",
    "for var in DEMO_CATEGORICAL:\n",
    "    summary = summarize_categorical(df, var, CLUSTER_COL)\n",
    "    row = {\"Variable\": DISPLAY_NAMES.get(var, var)}\n",
    "    for cl, col_name in zip(clusters, cluster_col_names):\n",
    "        row[col_name] = summary.get(cl, \"\")\n",
    "    row[\"P value\"] = summary[\"p\"]\n",
    "    rows.append(row)\n",
    "\n",
    "# 2) OTHER NUMERIC VARIABLES\n",
    "for var in OTHER_NUMERIC:\n",
    "    summary = summarize_numeric(df, var, CLUSTER_COL)\n",
    "    row = {\"Variable\": DISPLAY_NAMES.get(var, var)}\n",
    "    for cl, col_name in zip(clusters, cluster_col_names):\n",
    "        row[col_name] = summary.get(cl, \"\")\n",
    "    row[\"P value\"] = summary[\"p\"]\n",
    "    rows.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0d58170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file created: cluster_summary_table.xlsx\n",
      "Cluster sizes: {'0': np.int64(56), '1': np.int64(54), '2': np.int64(55), '3': np.int64(56)}\n"
     ]
    }
   ],
   "source": [
    "# Create final table\n",
    "table_df = pd.DataFrame(rows, columns=[\"Variable\"] + cluster_col_names + [\"P value\"])\n",
    "\n",
    "# Save to Excel\n",
    "with pd.ExcelWriter(OUTPUT_XLSX, engine=\"openpyxl\") as writer:\n",
    "    table_df.to_excel(writer, index=False, sheet_name=\"Cluster Summary\")\n",
    "\n",
    "print(\"Excel file created:\", OUTPUT_XLSX)\n",
    "print(\"Cluster sizes:\", cluster_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effe907a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster ‚Üí Symbol mapping: {np.int64(0): '*', np.int64(1): '#', np.int64(2): '$', np.int64(3): '%'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "- Read cluster labels and assign each cluster a significance symbol (* # $ % ...).\n",
    "- These symbols will be used later to mark ‚Äúsignificant difference from Cx‚Äù.\n",
    "\"\"\"\n",
    "\n",
    "# ========= CONFIG =========\n",
    "FILE = \"cluster_sample.csv\"      # <-- put your xlsx filename here\n",
    "CLUSTER_COL = \"cluster\"         # <-- name of your cluster column\n",
    "\n",
    "# tell the script which variables are nominal and which are ordinal\n",
    "NOMINAL_VARS = [\"gender\", \"marital\"]      # edit if names differ\n",
    "ORDINAL_VARS = [\"education\", \"income\"]    # numeric codes with order\n",
    "\n",
    "ALPHA = 0.05\n",
    "\n",
    "# Ensure cluster is treated as category-like\n",
    "clusters = sorted(df[CLUSTER_COL].dropna().unique())\n",
    "\n",
    "# Map each cluster to a symbol (first 4)\n",
    "symbol_list = [\"*\", \"#\", \"$\", \"%\", \"&\", \"@\"]  # just in case >4 clusters\n",
    "cluster_to_symbol = {c: symbol_list[i] for i, c in enumerate(clusters)}\n",
    "print(\"Cluster ‚Üí Symbol mapping:\", cluster_to_symbol)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312996eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Helper functions for Bonferroni correction and marker-table creation.\n",
    "\n",
    "Functions:\n",
    "- bonferroni_correct(p_values):\n",
    "    Applies Bonferroni correction to a list of p-values.\n",
    "    Formula: p_corrected = min(p * number_of_tests, 1)\n",
    "\n",
    "- empty_marker_table():\n",
    "    Creates an empty table with clusters as columns and no rows yet.\n",
    "    This table will later be filled with symbols (*, #, $, ...) indicating\n",
    "    which clusters differ significantly from which.\n",
    "\"\"\"\n",
    "\n",
    "def bonferroni_correct(p_values):\n",
    "    \"\"\"Simple Bonferroni correction: p * m, clipped to 1.\"\"\"\n",
    "    m = len(p_values)\n",
    "    return [min(p * m, 1.0) for p in p_values]\n",
    "\n",
    "def empty_marker_table():\n",
    "    \"\"\"Create an empty marker table: rows=variables, cols=clusters.\"\"\"\n",
    "    return pd.DataFrame(\"\", index=[], columns=clusters)\n",
    "\n",
    "# we‚Äôll fill two marker tables:\n",
    "markers_numeric = empty_marker_table()\n",
    "markers_nominal = empty_marker_table()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b93017",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Statistical testing for numeric and ordinal variables.\n",
    "\n",
    "Process:\n",
    "1. Automatically extract all numeric variables.\n",
    "2. Remove variables that should not be treated as numeric\n",
    "   (cluster column, nominal variables).\n",
    "3. For each variable:\n",
    "    - Split values by cluster.\n",
    "    - Run Kruskal‚ÄìWallis test (non-parametric general test across >2 groups).\n",
    "    - If significant:\n",
    "         * perform pairwise Mann‚ÄìWhitney tests between cluster pairs.\n",
    "         * apply Bonferroni correction.\n",
    "         * write symbols indicating which clusters differ.\n",
    "\"\"\"\n",
    "\n",
    "# ---- find numeric variables automatically ----\n",
    "numeric_all = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# remove cluster and nominal (they are coded as numbers but not numeric)\n",
    "for c in [CLUSTER_COL] + NOMINAL_VARS:\n",
    "    if c in numeric_all:\n",
    "        numeric_all.remove(c)\n",
    "\n",
    "# numeric_all now contains: ordinal + continuous variables\n",
    "# we will treat all of them with Kruskal + Mann‚ÄìWhitney (non-parametric)\n",
    "\n",
    "for var in numeric_all:\n",
    "    data = df[[CLUSTER_COL, var]].dropna()\n",
    "    if data.empty:\n",
    "        continue\n",
    "\n",
    "    # groups per cluster\n",
    "    groups = [data[data[CLUSTER_COL] == c][var].values for c in clusters]\n",
    "\n",
    "    # --- General test: Kruskal‚ÄìWallis ---\n",
    "    if len(groups) >= 2:\n",
    "        stat, p_general = kruskal(*groups)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    if p_general >= ALPHA:\n",
    "        # no overall difference ‚Üí no marks\n",
    "        continue\n",
    "\n",
    "    # --- Pairwise Mann‚ÄìWhitney with Bonferroni ---\n",
    "    pair_names = []\n",
    "    pair_ps = []\n",
    "\n",
    "    for c1, c2 in combinations(clusters, 2):\n",
    "        g1 = data[data[CLUSTER_COL] == c1][var].values\n",
    "        g2 = data[data[CLUSTER_COL] == c2][var].values\n",
    "        if len(g1) == 0 or len(g2) == 0:\n",
    "            continue\n",
    "\n",
    "        _, p_pair = mannwhitneyu(g1, g2, alternative=\"two-sided\")\n",
    "        pair_names.append((c1, c2))\n",
    "        pair_ps.append(p_pair)\n",
    "\n",
    "    if not pair_ps:\n",
    "        continue\n",
    "\n",
    "    pair_ps_corr = bonferroni_correct(pair_ps)\n",
    "\n",
    "    # --- Build markers for this variable ---\n",
    "    # start with empty marks for each cluster\n",
    "    marks_for_var = {c: \"\" for c in clusters}\n",
    "\n",
    "    for (c1, c2), p_corr in zip(pair_names, pair_ps_corr):\n",
    "        if p_corr < ALPHA:\n",
    "            # c1 is different from c2 ‚Üí in the cell for c1 we add symbol of c2\n",
    "            marks_for_var[c1] += cluster_to_symbol[c2]\n",
    "            # and symmetric: c2 is different from c1 ‚Üí add symbol of c1\n",
    "            marks_for_var[c2] += cluster_to_symbol[c1]\n",
    "\n",
    "    # write row into markers_numeric\n",
    "    markers_numeric.loc[var] = pd.Series(marks_for_var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0133fbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Statistical testing for nominal (categorical) variables.\n",
    "\n",
    "Process:\n",
    "1. Construct a contingency table: categories √ó clusters.\n",
    "2. Clean table by removing rows/columns with zero total.\n",
    "3. Perform Chi-square test to detect overall association.\n",
    "4. If significant:\n",
    "       * perform pairwise cluster comparisons using Chi-square\n",
    "         or Fisher's exact test (for 2√ó2 tables or low expected counts).\n",
    "       * apply Bonferroni correction.\n",
    "       * assign symbols indicating which clusters differ.\n",
    "\"\"\"\n",
    "\n",
    "results_nom = []\n",
    "\n",
    "for var in NOMINAL_VARS:\n",
    "    data = df[[CLUSTER_COL, var]].dropna()\n",
    "    if data.empty:\n",
    "        continue\n",
    "\n",
    "    contingency = pd.crosstab(data[var], data[CLUSTER_COL])\n",
    "\n",
    "    # üßπ Remove rows/cols with zero total ‚Äì they break chi2\n",
    "    contingency = contingency.loc[contingency.sum(axis=1) > 0, :]\n",
    "    contingency = contingency.loc[:, contingency.sum(axis=0) > 0]\n",
    "\n",
    "    # if <2 clusters or <2 categories left, we can‚Äôt test ‚Üí skip\n",
    "    if contingency.shape[0] < 2 or contingency.shape[1] < 2:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        chi2, p_general, dof, expected = chi2_contingency(contingency)\n",
    "    except ValueError:\n",
    "        # still problematic (rare) ‚Üí skip this variable\n",
    "        continue\n",
    "\n",
    "    if p_general >= ALPHA:\n",
    "        # no overall association ‚Üí no marks\n",
    "        continue\n",
    "\n",
    "    # small expected counts? ‚Üí use Fisher for 2x2 pairwise\n",
    "    use_fisher = (expected < 5).any()\n",
    "\n",
    "    pair_names = []\n",
    "    pair_ps = []\n",
    "\n",
    "    for c1, c2 in combinations(contingency.columns, 2):\n",
    "        table2 = contingency[[c1, c2]]\n",
    "\n",
    "        if use_fisher and table2.shape == (2, 2):\n",
    "            _, p_pair = fisher_exact(table2.values)\n",
    "            pair_test = \"Fisher\"\n",
    "        else:\n",
    "            try:\n",
    "                _, p_pair, _, _ = chi2_contingency(table2)\n",
    "                pair_test = \"Chi-square\"\n",
    "            except ValueError:\n",
    "                # if still invalid, skip this pair\n",
    "                continue\n",
    "\n",
    "        pair_names.append((c1, c2))\n",
    "        pair_ps.append(p_pair)\n",
    "\n",
    "    if not pair_ps:\n",
    "        continue\n",
    "\n",
    "    pair_ps_corr = bonferroni_correct(pair_ps)\n",
    "\n",
    "    # build symbols for this nominal variable\n",
    "    marks_for_var = {c: \"\" for c in clusters}\n",
    "\n",
    "    for (c1, c2), p_corr in zip(pair_names, pair_ps_corr):\n",
    "        if p_corr < ALPHA:\n",
    "            # c1 differs from c2 ‚Üí add symbol of c2 in row c1\n",
    "            if c2 in cluster_to_symbol:\n",
    "                marks_for_var[c1] += cluster_to_symbol[c2]\n",
    "            # and symmetric\n",
    "            if c1 in cluster_to_symbol:\n",
    "                marks_for_var[c2] += cluster_to_symbol[c1]\n",
    "\n",
    "    markers_nominal.loc[var] = pd.Series(marks_for_var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ccf2c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      " - markers_numeric_ordinal.xlsx\n",
      " - markers_nominal.xlsx\n"
     ]
    }
   ],
   "source": [
    "markers_numeric.to_excel(\"markers_numeric_ordinal.xlsx\")\n",
    "markers_nominal.to_excel(\"markers_nominal.xlsx\")\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\" - markers_numeric_ordinal.xlsx\")\n",
    "print(\" - markers_nominal.xlsx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e588515",
   "metadata": {},
   "source": [
    "Results reflect:\n",
    "\n",
    "\n",
    "Cluster 0: the Overwhelmed Student Looking for Support\n",
    "\n",
    "Mostly females, often married, with lower income and elementary‚Äìto‚Äìhigh-school education. They show **moderate** alcohol, drug, and internet-addiction scores, along with mid-level well-being and trauma exposure. Mia represents adults who face daily pressures and rely on emotional support systems, navigating life with limited economic resources.\n",
    "\n",
    "Cluster 1: the Social Drinker on the Edge\n",
    "\n",
    "Predominantly male, married, with lower educational background and mid-range income. They show **the lowest** internet-addiction scores but **elevated alcohol-use and gambling-risk levels**, along with **lower life satisfaction** and emotional well-being. Marko reflects adults who cope socially through substance use while struggling with emotional stability.\n",
    "\n",
    "Cluster 2: the Always-Online Friend\n",
    "\n",
    "Mostly single individuals with higher education (often Master‚Äôs degree) and **the highest income**. They show **very high internet-use scores**, moderate gambling and alcohol risk, and **strong well-being, social support, and life satisfaction**. Alex represents a digitally engaged, high-achieving adult who maintains good emotional health despite heavy online activity.\n",
    "\n",
    "Cluster 3: the Caring Professional with High Well-Being\n",
    "\n",
    "Predominantly women, often with middle-school to higher education and low-to-mid income. They show moderate substance-use scores and high trauma exposure, but also **the strongest emotional well-being and social support** among all clusters. Sara represents resilient, socially connected adults who thrive emotionally despite facing life stressors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89579fe",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
