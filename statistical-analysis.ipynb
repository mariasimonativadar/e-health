{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecd6a3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from scipy.stats import kruskal, mannwhitneyu, chi2_contingency, fisher_exact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311b4478",
   "metadata": {},
   "source": [
    "Statistical analysis means that we want to see which columns are relevant and which are not that significantly relevant. I decided to look at the first 5 columns and do my reseach over them.\n",
    "\n",
    "First I have to decide on which column I wantto group my data first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c1333ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"filled_personal_medians.csv\" \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "personal_cols = [\"age\", \"gender\", \"education\", \"marital\", \"income\"]\n",
    "group_col = personal_cols[2]  # grouping variable (ordinal)\n",
    "alpha = 0.05              # significance level\n",
    "\n",
    "df = df[df[group_col].notna()].copy()\n",
    "\n",
    "# Select only numeric variables (exclude the grouping variable)\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if group_col in personal_cols:\n",
    "    num_cols.remove(group_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e8137a",
   "metadata": {},
   "source": [
    "Kruskal–Wallis tests across education levels\n",
    "We do Kruskal-Wallis because education is a quantitative variable, its value raises as the individual studied more:\n",
    "\n",
    "[5] Elementary school [8] Middle school [13] High School [18]Bachelor's Degree [22] Master's Degree [25] Doctoral Degree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "443efbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_results = []\n",
    "for col in num_cols:\n",
    "    grouped = [g[col].dropna().values for _, g in df[[group_col, col]].dropna().groupby(group_col)]\n",
    "    valid_groups = [arr for arr in grouped if len(arr) > 0]\n",
    "    if len(valid_groups) >= 2:\n",
    "        try:\n",
    "            stat, p = kruskal(*valid_groups)\n",
    "        except Exception:\n",
    "            stat, p = np.nan, np.nan\n",
    "        n = int(df[col].notna().sum())\n",
    "        kw_results.append((col, len(valid_groups), n, stat, p))\n",
    "\n",
    "kw_df = pd.DataFrame(kw_results, columns=[\"variable\", \"k_groups\", \"n_used\", \"kw_stat\", \"p_value\"])\n",
    "kw_df.sort_values(\"p_value\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a26131",
   "metadata": {},
   "source": [
    "Bonferroni correction (across all variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a7f9d1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Kruskal–Wallis (top 15 variables) ===\n",
      "       variable  k_groups  n_used     kw_stat       p_value        p_bonf  \\\n",
      "3        income         6     221  115.473575  2.851070e-23  2.936602e-21   \n",
      "96   DAST_total         6     221  103.924631  7.860045e-21  8.095847e-19   \n",
      "98   PGSI_total         6     221   99.398720  7.075754e-20  7.288026e-18   \n",
      "30       pgsi_7         6     221   65.289292  9.760915e-13  1.005374e-10   \n",
      "97    IAT_total         6     221   64.769401  1.251218e-12  1.288755e-10   \n",
      "50       iat_18         6     221   63.195152  2.652409e-12  2.731982e-10   \n",
      "14       dast_1         6     221   61.242997  6.725908e-12  6.927686e-10   \n",
      "40        iat_8         6     221   60.860068  8.071392e-12  8.313533e-10   \n",
      "102  WHO5_total         6     221   60.422840  9.939088e-12  1.023726e-09   \n",
      "27       pgsi_4         6     221   58.899338  2.051553e-11  2.113099e-09   \n",
      "101  SWLS_total         6     221   54.740921  1.475786e-10  1.520060e-08   \n",
      "20       dast_7         6     221   52.203601  4.900182e-10  5.047187e-08   \n",
      "48       iat_16         6     221   51.094369  8.272151e-10  8.520316e-08   \n",
      "26       pgsi_3         6     221   51.046561  8.460841e-10  8.714666e-08   \n",
      "45       iat_13         6     221   50.367253  1.165556e-09  1.200523e-07   \n",
      "\n",
      "     significant_bonf  \n",
      "3                True  \n",
      "96               True  \n",
      "98               True  \n",
      "30               True  \n",
      "97               True  \n",
      "50               True  \n",
      "14               True  \n",
      "40               True  \n",
      "102              True  \n",
      "27               True  \n",
      "101              True  \n",
      "20               True  \n",
      "48               True  \n",
      "26               True  \n",
      "45               True  \n",
      "\n",
      "Number of significant variables after Bonferroni: 78\n"
     ]
    }
   ],
   "source": [
    "m_tests = len(kw_df)\n",
    "kw_df[\"p_bonf\"] = (kw_df[\"p_value\"] * m_tests).clip(upper=1.0)\n",
    "kw_df[\"significant_bonf\"] = kw_df[\"p_bonf\"] < alpha\n",
    "\n",
    "print(\"\\n=== Kruskal–Wallis (top 15 variables) ===\")\n",
    "print(kw_df.head(15))\n",
    "print(\"\\nNumber of significant variables after Bonferroni:\", kw_df[\"significant_bonf\"].sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12575d3c",
   "metadata": {},
   "source": [
    "Post-hoc Mann–Whitney tests for significant variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a9588230",
   "metadata": {},
   "outputs": [],
   "source": [
    "posthoc_rows = []\n",
    "sig_vars = kw_df.loc[kw_df[\"significant_bonf\"], \"variable\"].tolist()\n",
    "\n",
    "edu_levels = sorted(df[group_col].dropna().unique())\n",
    "pairs = list(combinations(edu_levels, 2))\n",
    "m_pairs = len(pairs)\n",
    "\n",
    "for col in sig_vars:\n",
    "    for a, b in pairs:\n",
    "        A = df.loc[df[group_col] == a, col].dropna().values\n",
    "        B = df.loc[df[group_col] == b, col].dropna().values\n",
    "        if len(A) > 0 and len(B) > 0:\n",
    "            try:\n",
    "                u_stat, p = mannwhitneyu(A, B, alternative=\"two-sided\")\n",
    "            except Exception:\n",
    "                u_stat, p = np.nan, np.nan\n",
    "            p_corr = min(p * m_pairs, 1.0)\n",
    "            sig = p_corr < alpha\n",
    "            # rank-biserial correlation effect size\n",
    "            if not np.isnan(u_stat):\n",
    "                n1, n2 = len(A), len(B)\n",
    "                r_rb = 1 - (2*u_stat)/(n1*n2)\n",
    "            else:\n",
    "                r_rb = np.nan\n",
    "            posthoc_rows.append([col, a, b, len(A), len(B), u_stat, p, p_corr, sig, r_rb])\n",
    "\n",
    "posthoc_df = pd.DataFrame(\n",
    "    posthoc_rows,\n",
    "    columns=[\n",
    "        \"variable\", \"edu_a\", \"edu_b\", \"n_a\", \"n_b\", \"u_stat\",\n",
    "        \"p_value\", \"p_bonf\", \"significant_bonf\", \"rank_biserial_r\"\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b86c1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Significant variables after Bonferroni ===\n",
      "        variable  k_groups  n_used     kw_stat       p_value        p_bonf  \\\n",
      "98    PGSI_total        69     221  185.253722  8.390192e-13  8.641897e-11   \n",
      "96    DAST_total        69     221  184.097586  1.220510e-12  1.257125e-10   \n",
      "20        dast_7        69     221  164.882089  5.092588e-10  5.245366e-08   \n",
      "58        pcl5_6        69     221  161.247957  1.523499e-09  1.569204e-07   \n",
      "100  MSPSS_total        69     221  156.320665  6.561273e-09  6.758112e-07   \n",
      "102   WHO5_total        69     221  156.228211  6.741564e-09  6.943811e-07   \n",
      "56        pcl5_4        69     221  155.938173  7.339413e-09  7.559595e-07   \n",
      "53        pcl5_1        69     221  153.415594  1.529695e-08  1.575586e-06   \n",
      "101   SWLS_total        69     221  152.476920  2.006124e-08  2.066308e-06   \n",
      "87        swls_3        69     221  151.790289  2.444379e-08  2.517711e-06   \n",
      "2      education        69     221  151.737084  2.482025e-08  2.556486e-06   \n",
      "65       pcl5_13        69     221  148.984794  5.443524e-08  5.606829e-06   \n",
      "22        dast_9        69     221  147.697562  7.831186e-08  8.066122e-06   \n",
      "62       pcl5_10        69     221  147.609304  8.028227e-08  8.269074e-06   \n",
      "66       pcl5_14        69     221  146.359337  1.140108e-07  1.174311e-05   \n",
      "14        dast_1        69     221  145.726575  1.360452e-07  1.401266e-05   \n",
      "68       pcl5_16        69     221  144.251914  2.048958e-07  2.110426e-05   \n",
      "84      mspss_12        69     221  143.359022  2.621428e-07  2.700071e-05   \n",
      "97     IAT_total        69     221  142.723991  3.121217e-07  3.214854e-05   \n",
      "99    PCL5_total        69     221  142.013006  3.791919e-07  3.905677e-05   \n",
      "\n",
      "     significant_bonf  \n",
      "98               True  \n",
      "96               True  \n",
      "20               True  \n",
      "58               True  \n",
      "100              True  \n",
      "102              True  \n",
      "56               True  \n",
      "53               True  \n",
      "101              True  \n",
      "87               True  \n",
      "2                True  \n",
      "65               True  \n",
      "22               True  \n",
      "62               True  \n",
      "66               True  \n",
      "14               True  \n",
      "68               True  \n",
      "84               True  \n",
      "97               True  \n",
      "99               True  \n",
      "\n",
      "=== Post-hoc significant pairs (Bonferroni corrected) ===\n",
      "      variable  edu_a  edu_b  n_a  n_b  u_stat   p_value    p_bonf  \\\n",
      "5513    dast_7  21000  33000   13    7     0.0  0.000016  0.038127   \n",
      "57125   dast_2  21000  33000   13    7     0.0  0.000016  0.038127   \n",
      "\n",
      "       significant_bonf  rank_biserial_r  \n",
      "5513               True              1.0  \n",
      "57125              True              1.0  \n",
      "\n",
      "✅ Results saved as:\n",
      " - education_kruskal_bonferroni.csv\n",
      " - education_posthoc_mannwhitney_bonferroni.csv\n"
     ]
    }
   ],
   "source": [
    "kw_df.to_csv(\"statistical-analysis-results/education_kruskal_bonferroni.csv\", index=False)\n",
    "posthoc_df.to_csv(\"statistical-analysis-results/education_posthoc_mannwhitney_bonferroni.csv\", index=False)\n",
    "\n",
    "print(\"\\n=== Significant variables after Bonferroni ===\")\n",
    "print(kw_df[kw_df[\"significant_bonf\"]].head(20))\n",
    "\n",
    "print(\"\\n=== Post-hoc significant pairs (Bonferroni corrected) ===\")\n",
    "print(posthoc_df[posthoc_df[\"significant_bonf\"]].head(20))\n",
    "\n",
    "print(\"\\n✅ Results saved as:\")\n",
    "print(\" - education_kruskal_bonferroni.csv\")\n",
    "print(\" - education_posthoc_mannwhitney_bonferroni.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e4b3dc",
   "metadata": {},
   "source": [
    "KRUSKAL-WALLIS RESULTS\n",
    "\n",
    "variable - the name of the tested variable (column of the table)\n",
    "kgroups - nr of possible values for education (6)\n",
    "kw-stat - the statistic from doing Kruskal-Wallis (higher -> more difference between groups)\n",
    "p_Values - prob. or getting this difference by chaqnce\n",
    "p_bonf - prob after bonferroni correction\n",
    "significant_bonf - true if education influences the variable significantly\n",
    "\n",
    "interpretation of results: For 78 different variables in dataset, there are real, statistically significant differences between education levels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b970bba",
   "metadata": {},
   "source": [
    "POST-HOC RESULTS\n",
    "variable - same\n",
    "edu_a, edu_b - the 2 education levels being compared\n",
    "p_value - from mann-whitney (low means significant difference)\n",
    "p_bonf - bonferroni (<0.05 means significant difference)\n",
    "rank_biserial_r - \n",
    "    0.1 - small effect - weak difference\n",
    "    0.3 - medium - moderate difference\n",
    "    >0.5 - large - strong difference\n",
    "    >0 - higher scores in edu_a\n",
    "    <0 - higher scores in edu_b\n",
    "\n",
    "interpretation: it looked at only the 78 columns with differences, and then compared for each....category X of education vs category Y or education. For each pair it used Mann-Whitney U test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ff811a",
   "metadata": {},
   "source": [
    "Kruskal–Wallis: “Education matters for this variable.”\n",
    "\n",
    "Mann–Whitney (post-hoc): “Okay, which education levels differ, and by how much?”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b10083",
   "metadata": {},
   "source": [
    "** Ok now let's do the statistical analysis for a nominal variable (marital status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98098497",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"filled_personal_medians.csv\"   # <-- put your CSV filename here\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "group_col = \"marital\"   # grouping variable (nominal)\n",
    "alpha = 0.05\n",
    "\n",
    "# Keep only rows with a valid marital value\n",
    "df = df[df[group_col].notna()].copy()\n",
    "\n",
    "# Select only numeric variables (exclude the grouping variable)\n",
    "personal_cols = [\"age\", \"gender\", \"education\", \"marital\", \"income\"]\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if group_col in personal_cols:\n",
    "    num_cols.remove(group_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "193a6d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d00j849\\AppData\\Local\\Temp\\ipykernel_16328\\3167635844.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  categorized[col + \"_cat\"] = np.where(categorized[col] > median_val, \"High\", \"Low\")\n",
      "C:\\Users\\d00j849\\AppData\\Local\\Temp\\ipykernel_16328\\3167635844.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  categorized[col + \"_cat\"] = np.where(categorized[col] > median_val, \"High\", \"Low\")\n",
      "C:\\Users\\d00j849\\AppData\\Local\\Temp\\ipykernel_16328\\3167635844.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  categorized[col + \"_cat\"] = np.where(categorized[col] > median_val, \"High\", \"Low\")\n",
      "C:\\Users\\d00j849\\AppData\\Local\\Temp\\ipykernel_16328\\3167635844.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  categorized[col + \"_cat\"] = np.where(categorized[col] > median_val, \"High\", \"Low\")\n",
      "C:\\Users\\d00j849\\AppData\\Local\\Temp\\ipykernel_16328\\3167635844.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  categorized[col + \"_cat\"] = np.where(categorized[col] > median_val, \"High\", \"Low\")\n"
     ]
    }
   ],
   "source": [
    "# Chi-square and Fisher's tests work on categories, not continuous numbers.\n",
    "# So we’ll discretize each numeric variable into LOW / HIGH groups using the median.\n",
    "\n",
    "categorized = df.copy()\n",
    "for col in num_cols:\n",
    "    median_val = categorized[col].median()\n",
    "    categorized[col + \"_cat\"] = np.where(categorized[col] > median_val, \"High\", \"Low\")\n",
    "\n",
    "# Apply Chi-Square or Fisher’s Exact Test for each variable\n",
    "results = []\n",
    "\n",
    "for col in num_cols:\n",
    "    cat_col = col + \"_cat\"\n",
    "    contingency = pd.crosstab(categorized[group_col], categorized[cat_col])\n",
    "\n",
    "    # Check expected frequencies\n",
    "    if contingency.size == 0:\n",
    "        continue\n",
    "    chi2, p, dof, expected = chi2_contingency(contingency)\n",
    "\n",
    "    # If any expected cell < 5 → use Fisher (only works for 2x2)\n",
    "    if (expected < 5).any() and contingency.shape == (2, 2):\n",
    "        _, p_fisher = fisher_exact(contingency)\n",
    "        test_used = \"Fisher\"\n",
    "        p_final = p_fisher\n",
    "    else:\n",
    "        test_used = \"Chi-square\"\n",
    "        p_final = p\n",
    "\n",
    "    results.append({\n",
    "        \"variable\": col,\n",
    "        \"test_used\": test_used,\n",
    "        \"p_value\": p_final,\n",
    "        \"significant\": p_final < alpha\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "189b2e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Nominal Analysis (Marital) ===\n",
      "        variable   test_used       p_value  significant    p_bonf  \\\n",
      "3         income  Chi-square  6.587040e-08         True  0.000007   \n",
      "47        iat_15  Chi-square  1.630044e-07         True  0.000017   \n",
      "33         iat_1  Chi-square  1.792521e-07         True  0.000018   \n",
      "96    DAST_total  Chi-square  2.123482e-07         True  0.000022   \n",
      "43        iat_11  Chi-square  7.272538e-07         True  0.000075   \n",
      "39         iat_7  Chi-square  1.008457e-06         True  0.000104   \n",
      "41         iat_9  Chi-square  1.130483e-06         True  0.000116   \n",
      "35         iat_3  Chi-square  1.721982e-06         True  0.000177   \n",
      "97     IAT_total  Chi-square  3.041681e-06         True  0.000313   \n",
      "49        iat_17  Chi-square  3.388475e-06         True  0.000349   \n",
      "2      education  Chi-square  4.509672e-06         True  0.000464   \n",
      "42        iat_10  Chi-square  6.032723e-06         True  0.000621   \n",
      "51        iat_19  Chi-square  6.159800e-06         True  0.000634   \n",
      "100  MSPSS_total  Chi-square  9.491515e-06         True  0.000978   \n",
      "101   SWLS_total  Chi-square  9.491515e-06         True  0.000978   \n",
      "102   WHO5_total  Chi-square  9.491515e-06         True  0.000978   \n",
      "36         iat_4  Chi-square  9.495022e-06         True  0.000978   \n",
      "46        iat_14  Chi-square  1.031742e-05         True  0.001063   \n",
      "44        iat_12  Chi-square  1.494861e-05         True  0.001540   \n",
      "86        swls_2  Chi-square  1.837982e-05         True  0.001893   \n",
      "\n",
      "     significant_bonf  \n",
      "3                True  \n",
      "47               True  \n",
      "33               True  \n",
      "96               True  \n",
      "43               True  \n",
      "39               True  \n",
      "41               True  \n",
      "35               True  \n",
      "97               True  \n",
      "49               True  \n",
      "2                True  \n",
      "42               True  \n",
      "51               True  \n",
      "100              True  \n",
      "101              True  \n",
      "102              True  \n",
      "36               True  \n",
      "46               True  \n",
      "44               True  \n",
      "86               True  \n",
      "\n",
      "Number of significant variables (after Bonferroni): 30\n",
      "\n",
      "✅ Results saved as 'marital_chi_fisher_results.csv'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.sort_values(\"p_value\", inplace=True)\n",
    "results_df[\"p_bonf\"] = (results_df[\"p_value\"] * len(results_df)).clip(upper=1.0)\n",
    "results_df[\"significant_bonf\"] = results_df[\"p_bonf\"] < alpha\n",
    "\n",
    "results_df.to_csv(\"statistical-analysis-results/marital_chi_fisher_results.csv\", index=False)\n",
    "\n",
    "print(\"\\n=== Nominal Analysis (Marital) ===\")\n",
    "print(results_df.head(20))\n",
    "print(f\"\\nNumber of significant variables (after Bonferroni): {results_df['significant_bonf'].sum()}\")\n",
    "print(\"\\n✅ Results saved as 'marital_chi_fisher_results.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02899b14",
   "metadata": {},
   "source": [
    "columns were mentioned before\n",
    "here only 30 rows (out of 91 left) are significant. Means only 30 questiones of the quiestionnaire seem to have been influenced by the marital status of the person"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cff93e",
   "metadata": {},
   "source": [
    "Conclusion:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a462844",
   "metadata": {},
   "source": [
    "There are in total 95 variables (100 questions in the questionaire but we omit the personal cols, which are used here as gbrouping variables)\n",
    "\n",
    "age: zero relevant variables, could be removed\n",
    "gender: one relevant variable, could be removed\n",
    "education: 78 relevant vars, very important\n",
    "marital satus: 30 relevant vars, could be important but not really\n",
    "income: 66 relevant variables, pretty important"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
