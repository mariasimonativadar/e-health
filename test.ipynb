{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a84b8ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc3007c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 1) Set your file paths here ===\n",
    "CSV_PATHS = [\n",
    "    \"resources/dataset_project_eHealth20252026.csv\",\n",
    "    \"resources/questionnaire_codebook_eHealth20252026.csv\",\n",
    "]\n",
    " \n",
    "# (Optional) If you know the ID column name, set it here; otherwise the code will try to guess.\n",
    "KNOWN_ID_COL = None  # e.g., \"ID\" or \"RespondentID\" or \"participant_id\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf91a0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 2) Helper: robust CSV loader (handles common encodings/delimiters) \n",
    "def load_csv_robust(path: str) -> pd.DataFrame:\n",
    "    path = Path(path)\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {path}\")\n",
    "    # Try default; if it fails, try common alternatives\n",
    "    trials = [\n",
    "        dict(encoding=None, sep=None, engine=\"python\"),          # auto-detect sep\n",
    "        dict(encoding=\"utf-8\", sep=None, engine=\"python\"),\n",
    "        dict(encoding=\"latin-1\", sep=None, engine=\"python\"),\n",
    "        dict(encoding=None, sep=\",\", engine=\"python\"),\n",
    "        dict(encoding=None, sep=\";\", engine=\"python\"),\n",
    "    ]\n",
    "    last_err = None\n",
    "    for kw in trials:\n",
    "        try:\n",
    "            return pd.read_csv(path, **kw)\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "    raise RuntimeError(f\"Could not read {path} – last error:\\n{last_err}\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c1ea95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Loaded: resources/dataset_project_eHealth20252026.csv ===\n",
      "Shape: 221 rows × 96 cols\n",
      "First 20 column names: ['age', 'gender', 'education', 'marital', 'income', 'audit_1', 'audit_2', 'audit_3', 'audit_4', 'audit_5', 'audit_6', 'audit_7', 'audit_8', 'audit_9', 'audit_10', 'dast_1', 'dast_2', 'dast_3', 'dast_4', 'dast_5']\n",
      "\n",
      "Dtypes:\n",
      "age          float64\n",
      "gender         int64\n",
      "education    float64\n",
      "marital      float64\n",
      "income         int64\n",
      "audit_1        int64\n",
      "audit_2        int64\n",
      "audit_3      float64\n",
      "audit_4        int64\n",
      "audit_5      float64\n",
      "audit_6        int64\n",
      "audit_7      float64\n",
      "audit_8      float64\n",
      "audit_9      float64\n",
      "audit_10     float64\n",
      "dtype: object\n",
      "\n",
      "=== Loaded: resources/questionnaire_codebook_eHealth20252026.csv ===\n",
      "Shape: 96 rows × 4 cols\n",
      "First 20 column names: ['\\ufeffquestion', 'type', 'name of column', '[codification] options (if applicable)']\n",
      "\n",
      "Dtypes:\n",
      "﻿question                                 object\n",
      "type                                      object\n",
      "name of column                            object\n",
      "[codification] options (if applicable)    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# === 3) Load both CSVs and show basic info ===\n",
    "for p in CSV_PATHS:\n",
    "    df = load_csv_robust(p)\n",
    "    print(f\"\\n=== Loaded: {p} ===\")\n",
    "    print(f\"Shape: {df.shape[0]} rows × {df.shape[1]} cols\")\n",
    "    print(\"First 20 column names:\", list(df.columns[:20]))\n",
    "    print(\"\\nDtypes:\")\n",
    "    print(df.dtypes.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6620c3f",
   "metadata": {},
   "source": [
    "We need to do some cleaning in dataset csv \n",
    "For the Nan values, replace NaN with the mean values of that question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c4e7b6",
   "metadata": {},
   "source": [
    "Each prefix is the abbreviation for a different questionnaire or scale:\n",
    "\n",
    "audit: Alcohol Use Disorders Identification Test\n",
    "\n",
    "dast: Drug Abuse Screening Test\n",
    "\n",
    "pgsi: Problem Gambling Severity Index\n",
    "\n",
    "iat: Internet Addiction Test\n",
    "\n",
    "pcl5: PTSD Checklist for DSM-5\n",
    "\n",
    "mspss: Multidimensional Scale of Perceived Social Support\n",
    "\n",
    "swls: Satisfaction With Life Scale\n",
    "\n",
    "who5: WHO-5 Well-Being Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdaba45",
   "metadata": {},
   "outputs": [],
   "source": [
    "questionnaires = [\n",
    "    \"audit\",\n",
    "    \"dast\",\n",
    "    \"pgsi\",\n",
    "    \"iat\",\n",
    "    \"pcl5\",\n",
    "    \"mspss\",\n",
    "    \"swls\",\n",
    "    \"who5\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e43bc4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN rows in df1: 67\n",
      "Rows with NaN or empty string values: [2, 6, 8, 13, 17, 18, 28, 29, 31, 35, 37, 39, 49, 53, 57, 59, 61, 62, 64, 66, 68, 69, 74, 79, 82, 83, 88, 91, 92, 95, 96, 100, 105, 107, 109, 110, 111, 114, 115, 116, 117, 120, 122, 129, 132, 133, 140, 141, 142, 149, 151, 156, 157, 162, 165, 170, 173, 181, 183, 195, 199, 201, 204, 206, 214, 215, 219]\n"
     ]
    }
   ],
   "source": [
    "#Clean data\n",
    "\n",
    "dataset = load_csv_robust(CSV_PATHS[0])\n",
    "nan_rows_df1 = dataset.isna().any(axis=1).sum()\n",
    "\n",
    "print(f\"NaN rows in df1: {nan_rows_df1}\")\n",
    "\n",
    "# Suppose your DataFrame is called dataset\n",
    "flag_nan_or_empty = dataset.isna() | (dataset == \"\")\n",
    "nan_or_empty_rows = dataset.index[flag_nan_or_empty.any(axis=1)].tolist()\n",
    "\n",
    "print(f\"Rows with NaN or empty string values: {nan_or_empty_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b71da455",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'gender'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\d00j849\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'gender'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# # Fill numeric columns age and income with their median\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# for col in ['age', 'income']:\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m#     median_val = df[col].median(skipna=True)\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m#     df_filled[col] = df[col].fillna(median_val)\u001b[39;00m\n\u001b[32m     24\u001b[39m \n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Fill categorical-coded columns (gender, education, marital) with their mode (most frequent value)\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33mgender\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33meducation\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmarital\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     mode_val = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m.mode(dropna=\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[32m0\u001b[39m]\n\u001b[32m     28\u001b[39m     df_filled[col] = df[col].fillna(mode_val)\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Save the filled dataset locally with a new name\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\d00j849\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\d00j849\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'gender'"
     ]
    }
   ],
   "source": [
    "dataset.columns = dataset.columns.str.strip()\n",
    "\n",
    "df_filled = dataset.copy()\n",
    "\n",
    "# Get only the questionnaire columns (skipping demographic first 5)\n",
    "questionnaire_cols = dataset.columns[5:]\n",
    "\n",
    "for q in questionnaires:\n",
    "    q_cols = [col for col in questionnaire_cols if col.startswith(q + \"_\")]\n",
    "    dataset[q_cols] = dataset[q_cols].replace(\"\", np.nan)\n",
    "    dataset[q_cols] = dataset[q_cols].apply(pd.to_numeric, errors='coerce')\n",
    "    for idx, row in dataset.iterrows():\n",
    "        med = row[q_cols].median(skipna=True)\n",
    "        df_filled.loc[idx, q_cols] = row[q_cols].fillna(med)\n",
    "\n",
    "\n",
    "# Columns to process \n",
    "demo_cols = ['age', 'gender', 'education', 'marital', 'income']\n",
    "\n",
    "# # Fill numeric columns age and income with their median\n",
    "# for col in ['age', 'income']:\n",
    "#     median_val = df[col].median(skipna=True)\n",
    "#     df_filled[col] = df[col].fillna(median_val)\n",
    "\n",
    "# Fill categorical-coded columns (gender, education, marital) with their mode (most frequent value)\n",
    "for col in ['gender', 'education', 'marital']:\n",
    "    mode_val = df[col].mode(dropna=True)[0]\n",
    "    df_filled[col] = df[col].fillna(mode_val)\n",
    "\n",
    "# Save the filled dataset locally with a new name\n",
    "df_filled.to_csv('filled_personal_medians.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a1a32657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'gender', 'education', 'marital', 'income', 'audit_1', 'audit_2', 'audit_3', 'audit_4', 'audit_5', 'audit_6', 'audit_7', 'audit_8', 'audit_9', 'audit_10', 'dast_1', 'dast_2', 'dast_3', 'dast_4', 'dast_5', 'dast_6', 'dast_7', 'dast_8', 'dast_9', 'dast_10', 'pgsi_1', 'pgsi_2', 'pgsi_3', 'pgsi_4', 'pgsi_5', 'pgsi_6', 'pgsi_7', 'pgsi_8', 'pgsi_9', 'iat_1', 'iat_2', 'iat_3', 'iat_4', 'iat_5', 'iat_6', 'iat_7', 'iat_8', 'iat_9', 'iat_10', 'iat_11', 'iat_12', 'iat_13', 'iat_14', 'iat_15', 'iat_16', 'iat_17', 'iat_18', 'iat_19', 'iat_20', 'pcl5_1', 'pcl5_2', 'pcl5_3', 'pcl5_4', 'pcl5_5', 'pcl5_6', 'pcl5_7', 'pcl5_8', 'pcl5_9', 'pcl5_10', 'pcl5_11', 'pcl5_12', 'pcl5_13', 'pcl5_14', 'pcl5_15', 'pcl5_16', 'pcl5_17', 'pcl5_18', 'pcl5_19', 'pcl5_20', 'mspss_1', 'mspss_2', 'mspss_3', 'mspss_4', 'mspss_5', 'mspss_6', 'mspss_7', 'mspss_8', 'mspss_9', 'mspss_10', 'mspss_11', 'mspss_12', 'swls_1', 'swls_2', 'swls_3', 'swls_4', 'swls_5', 'who5_1', 'who5_2', 'who5_3', 'who5_4', 'who5_5']\n"
     ]
    }
   ],
   "source": [
    "print(dataset.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eba986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN rows in df1: 3\n",
      "Rows with NaN or empty string values: [8, 69, 162]\n"
     ]
    }
   ],
   "source": [
    "#Verify if data is clean\n",
    "\n",
    "nan_rows_df1 = df_filled.isna().any(axis=1).sum()\n",
    "\n",
    "print(f\"NaN rows in df1: {nan_rows_df1}\")\n",
    "\n",
    "# Suppose your DataFrame is called dataset\n",
    "flag_nan_or_empty = df_filled.isna() | (dataset == \"\")\n",
    "nan_or_empty_rows = df_filled.index[flag_nan_or_empty.any(axis=1)].tolist()\n",
    "\n",
    "print(f\"Rows with NaN or empty string values: {nan_or_empty_rows}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
