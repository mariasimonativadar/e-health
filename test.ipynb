{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a84b8ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc3007c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 1) Set your file paths here ===\n",
    "CSV_PATHS = [\n",
    "    \"resources/dataset_project_eHealth20252026.csv\",\n",
    "    \"resources/questionnaire_codebook_eHealth20252026.csv\",\n",
    "]\n",
    " \n",
    "# (Optional) If you know the ID column name, set it here; otherwise the code will try to guess.\n",
    "KNOWN_ID_COL = None  # e.g., \"ID\" or \"RespondentID\" or \"participant_id\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf91a0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 2) Helper: robust CSV loader (handles common encodings/delimiters) \n",
    "def load_csv_robust(path: str) -> pd.DataFrame:\n",
    "    path = Path(path)\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {path}\")\n",
    "    # Try default; if it fails, try common alternatives\n",
    "    trials = [\n",
    "        dict(encoding=None, sep=None, engine=\"python\"),          # auto-detect sep\n",
    "        dict(encoding=\"utf-8\", sep=None, engine=\"python\"),\n",
    "        dict(encoding=\"latin-1\", sep=None, engine=\"python\"),\n",
    "        dict(encoding=None, sep=\",\", engine=\"python\"),\n",
    "        dict(encoding=None, sep=\";\", engine=\"python\"),\n",
    "    ]\n",
    "    last_err = None\n",
    "    for kw in trials:\n",
    "        try:\n",
    "            return pd.read_csv(path, **kw)\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "    raise RuntimeError(f\"Could not read {path} – last error:\\n{last_err}\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39c1ea95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Loaded: resources/dataset_project_eHealth20252026.csv ===\n",
      "Shape: 221 rows × 96 cols\n",
      "First 20 column names: ['age', 'gender', 'education', 'marital', 'income', 'audit_1', 'audit_2', 'audit_3', 'audit_4', 'audit_5', 'audit_6', 'audit_7', 'audit_8', 'audit_9', 'audit_10', 'dast_1', 'dast_2', 'dast_3', 'dast_4', 'dast_5']\n",
      "\n",
      "Dtypes:\n",
      "age          float64\n",
      "gender         int64\n",
      "education    float64\n",
      "marital      float64\n",
      "income         int64\n",
      "audit_1        int64\n",
      "audit_2        int64\n",
      "audit_3      float64\n",
      "audit_4        int64\n",
      "audit_5      float64\n",
      "audit_6        int64\n",
      "audit_7      float64\n",
      "audit_8      float64\n",
      "audit_9      float64\n",
      "audit_10     float64\n",
      "dtype: object\n",
      "\n",
      "=== Loaded: resources/questionnaire_codebook_eHealth20252026.csv ===\n",
      "Shape: 96 rows × 4 cols\n",
      "First 20 column names: ['\\ufeffquestion', 'type', 'name of column', '[codification] options (if applicable)']\n",
      "\n",
      "Dtypes:\n",
      "﻿question                                 object\n",
      "type                                      object\n",
      "name of column                            object\n",
      "[codification] options (if applicable)    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# === 3) Load both CSVs and show basic info ===\n",
    "for p in CSV_PATHS:\n",
    "    df = load_csv_robust(p)\n",
    "    print(f\"\\n=== Loaded: {p} ===\")\n",
    "    print(f\"Shape: {df.shape[0]} rows × {df.shape[1]} cols\")\n",
    "    print(\"First 20 column names:\", list(df.columns[:20]))\n",
    "    print(\"\\nDtypes:\")\n",
    "    print(df.dtypes.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6620c3f",
   "metadata": {},
   "source": [
    "We need to do some cleaning in dataset csv \n",
    "For the Nan values, replace NaN with the mean values of that question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c4e7b6",
   "metadata": {},
   "source": [
    "Each prefix is the abbreviation for a different questionnaire or scale:\n",
    "\n",
    "audit: Alcohol Use Disorders Identification Test\n",
    "\n",
    "dast: Drug Abuse Screening Test\n",
    "\n",
    "pgsi: Problem Gambling Severity Index\n",
    "\n",
    "iat: Internet Addiction Test\n",
    "\n",
    "pcl5: PTSD Checklist for DSM-5\n",
    "\n",
    "mspss: Multidimensional Scale of Perceived Social Support\n",
    "\n",
    "swls: Satisfaction With Life Scale\n",
    "\n",
    "who5: WHO-5 Well-Being Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fdaba45",
   "metadata": {},
   "outputs": [],
   "source": [
    "questionnaires = [\n",
    "    \"audit\",\n",
    "    \"dast\",\n",
    "    \"pgsi\",\n",
    "    \"iat\",\n",
    "    \"pcl5\",\n",
    "    \"mspss\",\n",
    "    \"swls\",\n",
    "    \"who5\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e43bc4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN rows in df1: 67\n",
      "Rows with NaN or empty string values: [2, 6, 8, 13, 17, 18, 28, 29, 31, 35, 37, 39, 49, 53, 57, 59, 61, 62, 64, 66, 68, 69, 74, 79, 82, 83, 88, 91, 92, 95, 96, 100, 105, 107, 109, 110, 111, 114, 115, 116, 117, 120, 122, 129, 132, 133, 140, 141, 142, 149, 151, 156, 157, 162, 165, 170, 173, 181, 183, 195, 199, 201, 204, 206, 214, 215, 219]\n"
     ]
    }
   ],
   "source": [
    "#Clean data\n",
    "\n",
    "dataset = load_csv_robust(CSV_PATHS[0])\n",
    "nan_rows_df1 = dataset.isna().any(axis=1).sum()\n",
    "\n",
    "print(f\"NaN rows in df1: {nan_rows_df1}\")\n",
    "\n",
    "# Suppose your DataFrame is called dataset\n",
    "flag_nan_or_empty = dataset.isna() | (dataset == \"\")\n",
    "nan_or_empty_rows = dataset.index[flag_nan_or_empty.any(axis=1)].tolist()\n",
    "\n",
    "print(f\"Rows with NaN or empty string values: {nan_or_empty_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b71da455",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled = dataset.copy()\n",
    "\n",
    "# Get only the questionnaire columns (skipping demographic first 5)\n",
    "questionnaire_cols = dataset.columns[5:]\n",
    "\n",
    "for q in questionnaires:\n",
    "    q_cols = [col for col in questionnaire_cols if col.startswith(q + \"_\")]\n",
    "    dataset[q_cols] = dataset[q_cols].replace(\"\", np.nan)\n",
    "    dataset[q_cols] = dataset[q_cols].apply(pd.to_numeric, errors='coerce')\n",
    "    for idx, row in dataset.iterrows():\n",
    "        med = row[q_cols].median(skipna=True)\n",
    "        df_filled.loc[idx, q_cols] = row[q_cols].fillna(med)\n",
    "\n",
    "# Save the filled dataset locally with a new name\n",
    "df_filled.to_csv('filled_personal_medians.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51eba986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN rows in df1: 3\n"
     ]
    }
   ],
   "source": [
    "#Clean data\n",
    "\n",
    "nan_rows_df1 = df_filled.isna().any(axis=1).sum()\n",
    "\n",
    "print(f\"NaN rows in df1: {nan_rows_df1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5150cab",
   "metadata": {},
   "source": [
    "Filling numerical Nan values age and income with median and categorical with mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d39cc14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN BEFORE filling:\n",
      " age          1\n",
      "gender       0\n",
      "education    1\n",
      "marital      1\n",
      "income       0\n",
      "dtype: int64 \n",
      "\n",
      "✅ age: filled NaN with median = 29.0\n",
      "✅ gender: filled NaN with median = 1.0\n",
      "✅ education: filled NaN with median = 13.0\n",
      "✅ marital: filled NaN with median = 1.0\n",
      "✅ income: filled NaN with median = 25000.0\n",
      "\n",
      "NaN AFTER filling:\n",
      " age          0\n",
      "gender       0\n",
      "education    0\n",
      "marital      0\n",
      "income       0\n",
      "dtype: int64\n",
      "\n",
      "✅ Updated 'filled_personal_medians.csv' saved — all NaN values replaced.\n"
     ]
    }
   ],
   "source": [
    "# Učitaj postojeći fajl\n",
    "df = pd.read_csv(\"filled_personal_medians.csv\")\n",
    "\n",
    "cols_to_fill = [\"age\", \"gender\", \"education\", \"marital\", \"income\"]\n",
    "\n",
    "print(\"NaN BEFORE filling:\\n\", df[cols_to_fill].isna().sum(), \"\\n\")\n",
    "\n",
    "for col in cols_to_fill:\n",
    "    if col not in df.columns:\n",
    "        print(f\"⚠️ Column '{col}' not found, skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Ako je numerička kolona → popuni medianom\n",
    "    if pd.api.types.is_numeric_dtype(df[col]):\n",
    "        med = df[col].median(skipna=True)\n",
    "        df[col] = df[col].fillna(med)\n",
    "        print(f\"✅ {col}: filled NaN with median = {med}\")\n",
    "\n",
    "    else:\n",
    "        # Ako je kategorijska → popuni modom (najčešćom vrednošću)\n",
    "        s = df[col].astype(\"string\").str.strip()\n",
    "        s = s.replace({\"\": pd.NA, \"nan\": pd.NA, \"None\": pd.NA})\n",
    "        mode_vals = s.mode(dropna=True)\n",
    "        if len(mode_vals) > 0:\n",
    "            mode_val = mode_vals[0]\n",
    "            df[col] = s.fillna(mode_val)\n",
    "            print(f\"✅ {col}: filled NaN with mode = '{mode_val}'\")\n",
    "        else:\n",
    "            df[col] = s.fillna(\"Unknown\")\n",
    "            print(f\"ℹ️ {col}: all values were NaN → filled with 'Unknown'\")\n",
    "\n",
    "print(\"\\nNaN AFTER filling:\\n\", df[cols_to_fill].isna().sum())\n",
    "\n",
    "# 💾 Prepiši originalni fajl (overwrite)\n",
    "df.to_csv(\"filled_personal_medians.csv\", index=False)\n",
    "print(\"\\n✅ Updated 'filled_personal_medians.csv' saved — all NaN values replaced.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93862466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Basic stats for first 5 personal columns ===\n",
      "age: min = 18.0, max = 40.0\n",
      "gender: min = 0, max = 3\n",
      "education: min = 5.0, max = 25.0\n",
      "marital: min = 0.0, max = 5.0\n",
      "income: min = 10000, max = 96600\n"
     ]
    }
   ],
   "source": [
    "personal_cols = [\"age\", \"gender\", \"education\", \"marital\", \"income\"]\n",
    "\n",
    "print(\"\\n=== Basic stats for first 5 personal columns ===\")\n",
    "for col in personal_cols:\n",
    "    if col not in df.columns:\n",
    "        print(f\"⚠️ Column '{col}' not found in dataset — skipping.\")\n",
    "        continue\n",
    "    \n",
    "    # ako je numerička kolona → prikaz min i max\n",
    "    if pd.api.types.is_numeric_dtype(df[col]):\n",
    "        col_min = df[col].min(skipna=True)\n",
    "        col_max = df[col].max(skipna=True)\n",
    "        print(f\"{col}: min = {col_min}, max = {col_max}\")\n",
    "    else:\n",
    "        # ako je kategorijska kolona → prikaži broj unikatnih i top 3 vrednosti\n",
    "        unique_vals = df[col].dropna().unique()\n",
    "        print(f\"{col}: {len(unique_vals)} unique values → {df[col].value_counts().head(3).to_dict()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
